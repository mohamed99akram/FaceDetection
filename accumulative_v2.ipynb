{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "    def __init__(self, feature_index, feature_val, threshold, polarity, error):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.error = error\n",
    "    \n",
    "    # make a function for easier access as numpy array, example: np.array(wc)\n",
    "    def __array__(self):\n",
    "        # return tensor.cpu() if members are tensors else np.array\n",
    "        if type(self.feature_index) == torch.Tensor:\n",
    "            return np.array([self.feature_index.cpu().numpy(), self.feature_val.cpu().numpy(), self.threshold.cpu().numpy(), self.polarity.cpu().numpy(), self.error.cpu().numpy()])\n",
    "        else:\n",
    "            return np.array([self.feature_index, self.feature_val, self.threshold, self.polarity, self.error])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return np.array(self).__str__()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # n_features = 16000\n",
    "# # n_samples = 15000\n",
    "n_features = 5\n",
    "n_samples = 15\n",
    "n_classes = 2\n",
    "X = np.random.randn(n_features, n_samples)\n",
    "y = np.random.randint(0, n_classes, n_samples)\n",
    "# y = np.array([1 if i == 1 else -1 for i in y])\n",
    "# generate random positive weights\n",
    "weights = np.random.rand(n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X.npy', X)\n",
    "# np.save('y.npy', y)\n",
    "# np.save('weights.npy', weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "# y[y==0] = -1\n",
    "weights = np.load('weights.npy')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.002636 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "\n",
    "total_pos, total_neg = 0, 0\n",
    "for w, label in zip(weights, y):\n",
    "    if label == 1:\n",
    "        total_pos += w\n",
    "    else:\n",
    "        total_neg += w\n",
    "\n",
    "classifiers = []\n",
    "total_features = X.shape[0]\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "    applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "    pos_seen, neg_seen = 0, 0\n",
    "    pos_weights, neg_weights = 0, 0\n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "    current_idx = 0\n",
    "    ws = []\n",
    "    last_error = 0\n",
    "    pos_seen_list = []\n",
    "    for w, f, label in applied_feature:\n",
    "        ws.append(w)\n",
    "        # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "        # error = sum of weights of misclassified examples\n",
    "        error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "        last_error = error\n",
    "        # print(\"error : \", error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            # best_feature = features[index]\n",
    "            best_feature = (current_idx, f)\n",
    "            best_threshold = f\n",
    "            best_polarity = 1 if pos_seen > neg_seen else -1\n",
    "\n",
    "        if label == 1:\n",
    "            pos_seen += 1\n",
    "            pos_weights += w\n",
    "        else:\n",
    "            neg_seen += 1\n",
    "            neg_weights += w\n",
    "        current_idx += 1\n",
    "        pos_seen_list.append(pos_seen)\n",
    "\n",
    "    # clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity)\n",
    "    clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine\n",
    "\n",
    "<h3>\n",
    "<div style='color: red;'>\n",
    "Question: for the polarity:<br>\n",
    " Direction that gives minimum weights <span style='color:pink'> -> To be consistent with finding minimum error using weights</span><br> \n",
    "    or<br>\n",
    " Direction that gives less misclassified samples???? <span style='color:pink'> -> To find threshold giving better accuracy???</span></div>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.003728 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "classifiers2 = []\n",
    "total_features2 = X.shape[0]\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers2) % 1000 == 0 and len(classifiers2) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers2), total_features2))\n",
    "        \n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok?\n",
    "    sorting_indecies = np.lexsort((y, weights, feature))\n",
    "    \n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w, s_f, s_y = weights[sorting_indecies], feature[sorting_indecies], y[sorting_indecies]\n",
    "    \n",
    "    # for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "    for left, right in [(0, 1), (1, 0)]: #@ y: 0 or 1\n",
    "        left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left))))\n",
    "        right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right))))\n",
    "        right_weights = np.concatenate((right_weights, [0]))\n",
    "        idx = np.argmin(left_weights + right_weights)\n",
    "        if idx >= len(s_f):\n",
    "            idx = len(s_f) - 1\n",
    "            \n",
    "        cur_min_error = left_weights[idx] + right_weights[idx]\n",
    "        if cur_min_error < min_error:\n",
    "            min_error = cur_min_error\n",
    "            best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "            # best_polarity = left\n",
    "            best_polarity = -1 if left == 0 else 1\n",
    "\n",
    "    clf2 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers2.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more optimized?\n",
    "<h1>\n",
    "    <div style='color:red'>\n",
    "        Unfortunately, didn't work. The computer freezes when I try to run it.\n",
    "    </div>\n",
    "    <div style='color:red'>\n",
    "        Maybe will need to run it on a GPU??\n",
    "    </div>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_t = time.time()\n",
    "# classifiers3 = []\n",
    "# total_features3 = X.shape[0]\n",
    "\n",
    "# # TODO parallize this\n",
    "# # TODO can we get rid of this loop and make them matrices?\n",
    "# # for index, feature in enumerate(X):\n",
    "# #     if len(classifiers3) % 1000 == 0 and len(classifiers3) != 0:\n",
    "# #         print(\"Trained %d classifiers out of %d\" % (len(classifiers3), total_features3))\n",
    "        \n",
    "\n",
    "# min_error, best_feature, best_threshold, best_polarity = np.array([float('inf')]*X.shape[0])\\\n",
    "#     , np.zeros((X.shape[0], 2)), np.zeros(X.shape[0]), np.zeros(X.shape[0])\n",
    "\n",
    "# # sort by feature value first, then by weight, then by label\n",
    "# # TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "# weights2d = np.tile(weights, (X.shape[0], 1))\n",
    "# y2d = np.tile(y, (X.shape[0], 1))\n",
    "# sorting_indecies = np.lexsort((y2d\n",
    "#                                ,weights2d\n",
    "#                                ,X))\n",
    "# idx0 = np.arange(X.shape[0]).reshape(-1, 1)\n",
    "# # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "# s_w, s_f, s_y = weights2d[idx0, sorting_indecies], X[idx0, sorting_indecies], y2d[idx0, sorting_indecies]\n",
    "\n",
    "# for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "#     # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "#     left_weights = np.c_[np.zeros((s_w.shape[0], 1))\n",
    "#                          , np.cumsum(s_w * (s_y == left), axis=1)]\n",
    "#     right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right), axis = 1), axis=1), axis=1)\n",
    "#     # right_weights = np.concatenate((right_weights, [0]))\n",
    "#     right_weights = np.c_[right_weights, np.zeros((right_weights.shape[0], 1))]\n",
    "#     idx = np.argmin(left_weights + right_weights, axis=1)\n",
    "#     # should it be zero???\n",
    "#     idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "#     # if idx >= len(s_f):\n",
    "#     #     idx = len(s_f) - 1\n",
    "#     ii1 = np.arange(idx.shape[0])\n",
    "#     cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "#     temp_bool = cur_min_error < min_error\n",
    "#     min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "#     selected_idx = idx[temp_bool]\n",
    "#     selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "#     best_feature[temp_bool] = np.array(list(zip(selected_idx, selected_features)))\n",
    "#     best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "#     best_polarity[temp_bool] = left\n",
    "#     # if cur_min_error < min_error:\n",
    "#     #     min_error = cur_min_error\n",
    "#     #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "#     #     best_polarity = left\n",
    "# classifiers3 = [WeakClassifier(*clf3) for clf3 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "# # clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "# # classifiers3.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "# print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_features = 16000\n",
    "# n_samples = 15000\n",
    "# n_features = 3\n",
    "# n_samples = 10\n",
    "# n_classes = 2\n",
    "\n",
    "# X = torch.rand(n_features, n_samples, device=device)\n",
    "# y = torch.randint(0, n_classes, (n_samples, ))\n",
    "# y = torch.tensor([1 if i == 1 else -1 for i in y], device=device)\n",
    "# weights = torch.rand(n_samples, device=device)\n",
    "y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "weights = torch.tensor(weights, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0078125 Mb\n",
      "2.0 Mb\n"
     ]
    }
   ],
   "source": [
    "def mem(idx=None):\n",
    "    if idx:print('At index: ', idx, ': ')\n",
    "    print(torch.cuda.memory_allocated()/(1024**2), 'Mb')\n",
    "    print(torch.cuda.memory_reserved()/(1024**2), 'Mb')\n",
    "mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, n_features=3, n_samples=10):\n",
    "        self.X = torch.rand(n_features, n_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "dataset = FeaturesDataset(n_features=n_features, n_samples=n_samples)\n",
    "dataset.X = torch.tensor(X, dtype=torch.float32)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1000, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index:  0 :  Start time:  0.05659008026123047\n",
      "0.00830078125 Mb\n",
      "2.0 Mb\n",
      "0.0126953125 Mb\n",
      "2.0 Mb\n",
      "Time taken: 0.081751 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_t = time.time()\n",
    "\n",
    "classifiers4 = []\n",
    "total_features4 = n_features\n",
    "\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "# for index, feature in enumerate(X):\n",
    "#     if len(classifiers4) % 1000 == 0 and len(classifiers4) != 0:\n",
    "#         print(\"Trained %d classifiers out of %d\" % (len(classifiers4), total_features4))\n",
    "        \n",
    "for index, X in enumerate(dataloader):\n",
    "\n",
    "    print('At index: ', index, ':', ' Start time: ', time.time() - s_t)\n",
    "    X = X.to(device)\n",
    "    \n",
    "    mem(index)\n",
    "    min_error, best_feature, best_threshold, best_polarity = torch.tensor([float('inf')]*X.shape[0], device=device)\\\n",
    "        , torch.zeros((X.shape[0], 2), device=device), torch.zeros(X.shape[0], device=device), torch.zeros(X.shape[0], device=device)\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "    weights2d = torch.tile(weights, (X.shape[0], 1))\n",
    "    # del weights\n",
    "    y2d = torch.tile(y, (X.shape[0], 1))\n",
    "    # del y\n",
    "    # sorting_indecies = torch.lexsort((y2d\n",
    "    #                             ,weights2d\n",
    "    #                             ,X)).to(device)\n",
    "    sorting_indecies = torch.argsort(X,stable=True) \n",
    "    idx0 = torch.arange(X.shape[0]).reshape(-1, 1).to(device)\n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w = weights2d[idx0, sorting_indecies]\n",
    "    # del weights2d\n",
    "    s_f = X[idx0, sorting_indecies]\n",
    "    # del X\n",
    "    s_y = y2d[idx0, sorting_indecies]\n",
    "    # del y2d\n",
    "    # del idx0\n",
    "    \n",
    "    mem()\n",
    "\n",
    "\n",
    "    # for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "    for left, right in [(0, 1), (1, 0)]: #@ y: 0 or 1\n",
    "        # print(s_w.shape)\n",
    "        # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "        left_weights = torch.cat((torch.zeros((s_w.shape[0], 1), device=device)\n",
    "                            , torch.cumsum(s_w * (s_y == left), axis=1)), axis=1)\n",
    "        right_weights = torch.flip(torch.cumsum(torch.flip(s_w * (s_y == right), dims = [1]), axis=1), dims=[1])\n",
    "        # right_weights = np.concatenate((right_weights, [0]))\n",
    "        right_weights = torch.cat((right_weights, torch.zeros((right_weights.shape[0], 1), device=device)), axis=1)\n",
    "        idx = torch.argmin(left_weights + right_weights, axis=1)\n",
    "        # should it be zero???\n",
    "        idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "        # if idx >= len(s_f):\n",
    "        #     idx = len(s_f) - 1\n",
    "        ii1 = torch.arange(idx.shape[0], device=device)\n",
    "        cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "        temp_bool = cur_min_error < min_error\n",
    "        if temp_bool.any().item():\n",
    "            min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "            selected_idx = idx[temp_bool]\n",
    "            selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "\n",
    "            best_feature[temp_bool] = torch.tensor(list(zip(selected_idx, selected_features)), device=device)\n",
    "            best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "            # best_polarity[temp_bool] = left\n",
    "            best_polarity[temp_bool] = -1 if left == 0 else 1\n",
    "        # if cur_min_error < min_error:\n",
    "        #     min_error = cur_min_error\n",
    "        #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "        #     best_polarity = left\n",
    "    # add to classifiers4, converted to numpy\n",
    "    classifiers4.extend([WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)])\n",
    "    # classifiers4 = [WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "    # clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    # classifiers3.append(clf2)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.         -0.46927451 -0.46927451 -1.          0.22957901]\n",
      "[14.          2.55233053  2.55233053  1.          0.29585937]\n",
      "[ 2.         -0.55387062 -0.55387062 -1.          0.31632978]\n",
      "[12.          0.74379003  0.74379003  1.          0.33786842]\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "\n",
      "[ 2.         -0.46927451 -0.46927451  1.          0.22957901]\n",
      "[14.          2.55233053  2.55233053 -1.          0.29585937]\n",
      "[ 2.         -0.55387062 -0.55387062  1.          0.31632978]\n",
      "[12.          0.74379003  0.74379003 -1.          0.33786842]\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "\n",
      "[ 2.        -0.4692745 -0.4692745  1.         0.229579 ]\n",
      "[14.          2.5523305   2.5523305  -1.          0.29585937]\n",
      "[ 2.         -0.5538706  -0.5538706   1.          0.31632978]\n",
      "[12.          0.74379003  0.74379003 -1.          0.33786842]\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in classifiers:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers2:\n",
    "    print(el)\n",
    "print()\n",
    "# for el in classifiers3:\n",
    "#     print(el)\n",
    "# print()\n",
    "\n",
    "for el in classifiers4:\n",
    "    print(el)\n",
    "print()\n",
    "\n",
    "# classifiers==classifiers2\n",
    "# print(classifiers[0])\n",
    "# print(classifiers2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.         -0.46927451 -0.46927451 -1.          0.22957901]\n",
      "[ 2.         -0.46927451 -0.46927451  1.          0.22957901]\n",
      "[ 2.        -0.4692745 -0.4692745  1.         0.229579 ]\n",
      "\n",
      "[14.          2.55233053  2.55233053  1.          0.29585937]\n",
      "[14.          2.55233053  2.55233053 -1.          0.29585937]\n",
      "[14.          2.5523305   2.5523305  -1.          0.29585937]\n",
      "\n",
      "[ 2.         -0.55387062 -0.55387062 -1.          0.31632978]\n",
      "[ 2.         -0.55387062 -0.55387062  1.          0.31632978]\n",
      "[ 2.         -0.5538706  -0.5538706   1.          0.31632978]\n",
      "\n",
      "[12.          0.74379003  0.74379003  1.          0.33786842]\n",
      "[12.          0.74379003  0.74379003 -1.          0.33786842]\n",
      "[12.          0.74379003  0.74379003 -1.          0.33786842]\n",
      "\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "[ 7.         -0.05527531 -0.05527531  1.          0.27768317]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_features):\n",
    "    print(classifiers[i])\n",
    "    print(classifiers2[i])\n",
    "    print(classifiers4[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0224, 0.0148, 0.1099, 0.0669, 0.0072, 0.1079, 0.1228, 0.0964, 0.1067,\n",
       "        0.0381, 0.0111, 0.0663, 0.1238, 0.1052, 0.0004], device='cuda:0')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
