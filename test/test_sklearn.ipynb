{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../\")\n",
    "from feature_extractor import FeatureExtractor\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from cascade import CascadeClassifier\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent = '../hFeatures5/'\n",
    "data_path = 'new_data5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 111.02404842061983\n",
    "std = 56.926623499738575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform1(img):\n",
    "  return img\n",
    "  # img = (img - img.mean()) / (img.std() + 1e-8)\n",
    "  # return cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_extractor = FeatureExtractor(shape=(19,19),\n",
    "                                     percentile=20,\n",
    "                                     all_features_file=parent + \"all_features.npz\",\n",
    "                                     selected_features_file=parent + \"selected_features.npz\",\n",
    "                                     labels_file=parent + \"labels.npy\",\n",
    "                                     indecies_file=parent + \"indecies.npy\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = feature_extractor.extractFeatures(pos_path='../'+data_path+'/train/face',\n",
    "                                  neg_path='../'+data_path+'/train/non-face',\n",
    "                                  transform=transform1,\n",
    "                                  save_to_file=False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del feature_extractor.f2\n",
    "# del feature_extractor.f3\n",
    "# del feature_extractor.f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indecies, X = feature_extractor.selectPercentile(X, y )\n",
    "# y = np.load(parent + 'labels.npy')\n",
    "print(X.shape, y.shape)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = np.load('../hFeatures3/all_features.npz')['arr_0']\n",
    "temp = X\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp.min())\n",
    "print(temp.max())\n",
    "print(temp[3])\n",
    "print(temp[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[20]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost from sklearn with base_estimator = DecisionTreeClassifier with max_depth = 1 (stump) and n_estimators = 200\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Take X.T because sklearn expects (n_samples, n_features)\n",
    "X = X.T\n",
    "y = y.T\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "s_t = time.time()\n",
    "\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print('time:', time.time() - s_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %rm StrongClassifier/lastSC.last\n",
    "# s_t = time.time()\n",
    "# cascadeClassifier= CascadeClassifier(X, y, batchsize=5000, verbose=True, layers=[200])\n",
    "# tr_acc = cascadeClassifier.train()\n",
    "\n",
    "# cascadeClassifier.save(parent + 'cascadeClassifier.pkl')\n",
    "\n",
    "# print('accuracy: ', tr_acc)\n",
    "# print('time taken: ', time.time() - s_t, 's')\n",
    "# print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = feature_extractor.extractFeatures(pos_path='../'+data_path+'/test/face',\n",
    "                                  neg_path='../'+data_path+'/test/non-face',\n",
    "                                  transform=transform1,\n",
    "                                  save_to_file=False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[indecies]\n",
    "\n",
    "# convert from torch to numpy and take transpose\n",
    "X_test = X_test.cpu().numpy().T\n",
    "y_test = y_test.cpu().numpy()\n",
    "\n",
    "print(X_test.shape, y_test.shape)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_t = time.time()\n",
    "# t_f_idx_map, t_features, t_labels = feature_extractor.extractFeaturesByIndecies(pos_path='../'+data_path+'/test/face',\n",
    "#                                             neg_path='../'+data_path+'/test/non-face',\n",
    "#                                             cascadeClassifier=cascadeClassifier,\n",
    "#                                             transform=transform1)\n",
    "# print(t_features.shape, t_labels.shape)\n",
    "# predictions = cascadeClassifier.predict(t_features, t_f_idx_map)\n",
    "# print('test accuracy: ', np.sum(predictions == t_labels) / t_labels.shape[0])\n",
    "# print('time taken: ', time.time() - s_t, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "print('accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('f1 score macro: ', f1_score(y_test, y_pred, average='macro'))\n",
    "print('f1 score binary: ', f1_score(y_test, y_pred, average='binary'))\n",
    "print('f1 score micro: ', f1_score(y_test, y_pred, average='micro'))\n",
    "print('precision: ', precision_score(y_test, y_pred))\n",
    "print('recall: ', recall_score(y_test, y_pred))\n",
    "print('confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('classification report: \\n', classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir /content/drive/MyDrive/GP/GP_try/hFeatures5\n",
    "# !cp -r ../hFeatures5/* /content/drive/MyDrive/GP/GP_try/hFeatures5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../../lfw_all\n",
    "!cp /content/drive/MyDrive/GP/lfw_all/* ../../lfw_all/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from detect_face import find_face\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "lfw_all = '../../lfw_all/'\n",
    "all_images_names = os.listdir(lfw_all)\n",
    "# all_images_names = sorted(all_images_names)\n",
    "random.shuffle(all_images_names)\n",
    "all_images_names = [lfw_all + name for name in all_images_names]\n",
    "all_images_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images = list(range(0, 20))\n",
    "rectangles_only = True\n",
    "# resize_to = (100, 100)\n",
    "random.shuffle(all_images_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in show_images:\n",
    "  # >>>> Read image <<<<\n",
    "  img = Image.open(all_images_names[i])\n",
    "  print(img.mode)\n",
    "  img = np.array(img)\n",
    "  org_sh = img.shape\n",
    "  if not rectangles_only:\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "  # get subwindows\n",
    "  img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  print(img2.shape)\n",
    "\n",
    "  # >>>> Normalize image <<<<\n",
    "  # normalize image\n",
    "  # img2 = (img2 - img2.mean()) / img2.std()\n",
    "  # img2 = cv2.resize(img, resize_to)\n",
    "  # print(img2.shape)\n",
    "\n",
    "  # img2 = cv2.normalize(img2, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "  # resize image\n",
    "  # img2 = cv2.resize(img2, (570, 380))\n",
    "\n",
    "  # show image\n",
    "  if not rectangles_only:\n",
    "    plt.imshow(img2, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "  # +++++++++++++++++++++\n",
    "  # find face\n",
    "  # >>>> Find face <<<<\n",
    "  face_coordinates, region_max_conf, max_conf , timing=\\\n",
    "                  find_face(img2, \\\n",
    "                              clf, \\\n",
    "                              feature_extractor, \\\n",
    "                              window_size=(19, 19), \\\n",
    "                              scale_dist=1.1, \\\n",
    "                              max_size=300, \\\n",
    "                              stride=5, \\\n",
    "                              device=device, \\\n",
    "                              verbose=False,\n",
    "                              report_time=True,\n",
    "                              use_sklearn=True)\n",
    "  print(timing)\n",
    "  # region_max_conf *= img.shape[0] / resize_to[0]\n",
    "  # ++++++++++++++++++++\n",
    "  # rectangles\n",
    "  # >>>> Draw rectangles <<<<\n",
    "  tmp_img = img.copy()\n",
    "  for face_coordinate in face_coordinates:\n",
    "      for x1, y1, x2, y2 in face_coordinate:\n",
    "          cv2.rectangle(tmp_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "  # if not rectangles_only:\n",
    "  plt.imshow(tmp_img)\n",
    "  plt.show()\n",
    "\n",
    "  # >>>> Draw rectangles with max confidence <<<<\n",
    "  # amx confidence\n",
    "  tmp_img = img.copy()\n",
    "  x1, y1, x2, y2 = region_max_conf\n",
    "  cv2.rectangle(tmp_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "  plt.imshow(tmp_img)\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
