{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "    def __init__(self, feature_index, feature_val, threshold, polarity, error):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.error = error\n",
    "    \n",
    "    # make a function for easier access as numpy array, example: np.array(wc)\n",
    "    def __array__(self):\n",
    "        # return tensor.cpu() if members are tensors else np.array\n",
    "        if type(self.feature_index) == torch.Tensor:\n",
    "            return np.array([self.feature_index.cpu().numpy(), self.feature_val.cpu().numpy(), self.threshold.cpu().numpy(), self.polarity.cpu().numpy(), self.error.cpu().numpy()])\n",
    "        else:\n",
    "            return np.array([self.feature_index, self.feature_val, self.threshold, self.polarity, self.error])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return np.array(self).__str__()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 16000\n",
    "n_samples = 15000\n",
    "# n_features = 3\n",
    "# n_samples = 10\n",
    "n_classes = 2\n",
    "X = np.random.randn(n_features, n_samples)\n",
    "y = np.random.randint(0, n_classes, n_samples)\n",
    "y = np.array([1 if i == 1 else -1 for i in y])\n",
    "weights = np.random.randn(n_samples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1000 classifiers out of 16000\n",
      "Trained 2000 classifiers out of 16000\n",
      "Trained 3000 classifiers out of 16000\n",
      "Trained 4000 classifiers out of 16000\n",
      "Trained 5000 classifiers out of 16000\n",
      "Trained 6000 classifiers out of 16000\n",
      "Trained 7000 classifiers out of 16000\n",
      "Trained 8000 classifiers out of 16000\n",
      "Trained 9000 classifiers out of 16000\n",
      "Trained 10000 classifiers out of 16000\n",
      "Trained 11000 classifiers out of 16000\n",
      "Trained 12000 classifiers out of 16000\n",
      "Trained 13000 classifiers out of 16000\n",
      "Trained 14000 classifiers out of 16000\n",
      "Trained 15000 classifiers out of 16000\n",
      "Time taken: 345.721772 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "\n",
    "total_pos, total_neg = 0, 0\n",
    "for w, label in zip(weights, y):\n",
    "    if label == 1:\n",
    "        total_pos += w\n",
    "    else:\n",
    "        total_neg += w\n",
    "\n",
    "classifiers = []\n",
    "total_features = X.shape[0]\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "    applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "    pos_seen, neg_seen = 0, 0\n",
    "    pos_weights, neg_weights = 0, 0\n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "    current_idx = 0\n",
    "    ws = []\n",
    "    last_error = 0\n",
    "    pos_seen_list = []\n",
    "    for w, f, label in applied_feature:\n",
    "        ws.append(w)\n",
    "        # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "        # error = sum of weights of misclassified examples\n",
    "        error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "        last_error = error\n",
    "        # print(\"error : \", error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            # best_feature = features[index]\n",
    "            best_feature = (current_idx, f)\n",
    "            best_threshold = f\n",
    "            best_polarity = 1 if pos_seen > neg_seen else -1\n",
    "\n",
    "        if label == 1:\n",
    "            pos_seen += 1\n",
    "            pos_weights += w\n",
    "        else:\n",
    "            neg_seen += 1\n",
    "            neg_weights += w\n",
    "        current_idx += 1\n",
    "        pos_seen_list.append(pos_seen)\n",
    "\n",
    "    # clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity)\n",
    "    clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine\n",
    "\n",
    "<h3>\n",
    "<div style='color: red;'>\n",
    "Question: for the polarity:<br>\n",
    " Direction that gives minimum weights <span style='color:pink'> -> To be consistent with finding minimum error using weights</span><br> \n",
    "    or<br>\n",
    " Direction that gives less misclassified samples???? <span style='color:pink'> -> To find threshold giving better accuracy???</span></div>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1000 classifiers out of 16000\n",
      "Trained 2000 classifiers out of 16000\n",
      "Trained 3000 classifiers out of 16000\n",
      "Trained 4000 classifiers out of 16000\n",
      "Trained 5000 classifiers out of 16000\n",
      "Trained 6000 classifiers out of 16000\n",
      "Trained 7000 classifiers out of 16000\n",
      "Trained 8000 classifiers out of 16000\n",
      "Trained 9000 classifiers out of 16000\n",
      "Trained 10000 classifiers out of 16000\n",
      "Trained 11000 classifiers out of 16000\n",
      "Trained 12000 classifiers out of 16000\n",
      "Trained 13000 classifiers out of 16000\n",
      "Trained 14000 classifiers out of 16000\n",
      "Trained 15000 classifiers out of 16000\n",
      "Time taken: 37.049964 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "classifiers2 = []\n",
    "total_features2 = X.shape[0]\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers2) % 1000 == 0 and len(classifiers2) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers2), total_features2))\n",
    "        \n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok?\n",
    "    sorting_indecies = np.lexsort((y, weights, feature))\n",
    "    \n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w, s_f, s_y = weights[sorting_indecies], feature[sorting_indecies], y[sorting_indecies]\n",
    "    \n",
    "    for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "        left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left))))\n",
    "        right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right))))\n",
    "        right_weights = np.concatenate((right_weights, [0]))\n",
    "        idx = np.argmin(left_weights + right_weights)\n",
    "        if idx >= len(s_f):\n",
    "            idx = len(s_f) - 1\n",
    "            \n",
    "        cur_min_error = left_weights[idx] + right_weights[idx]\n",
    "        if cur_min_error < min_error:\n",
    "            min_error = cur_min_error\n",
    "            best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "            best_polarity = left\n",
    "\n",
    "    clf2 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers2.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more optimized?\n",
    "<h1>\n",
    "    <div style='color:red'>\n",
    "        Unfortunately, didn't work. The computer freezes when I try to run it.\n",
    "    </div>\n",
    "    <div style='color:red'>\n",
    "        Maybe will need to run it on a GPU??\n",
    "    </div>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.004261 seconds\n"
     ]
    }
   ],
   "source": [
    "# s_t = time.time()\n",
    "# classifiers3 = []\n",
    "# total_features3 = X.shape[0]\n",
    "\n",
    "# # TODO parallize this\n",
    "# # TODO can we get rid of this loop and make them matrices?\n",
    "# # for index, feature in enumerate(X):\n",
    "# #     if len(classifiers3) % 1000 == 0 and len(classifiers3) != 0:\n",
    "# #         print(\"Trained %d classifiers out of %d\" % (len(classifiers3), total_features3))\n",
    "        \n",
    "\n",
    "# min_error, best_feature, best_threshold, best_polarity = np.array([float('inf')]*X.shape[0])\\\n",
    "#     , np.zeros((X.shape[0], 2)), np.zeros(X.shape[0]), np.zeros(X.shape[0])\n",
    "\n",
    "# # sort by feature value first, then by weight, then by label\n",
    "# # TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "# weights2d = np.tile(weights, (X.shape[0], 1))\n",
    "# y2d = np.tile(y, (X.shape[0], 1))\n",
    "# sorting_indecies = np.lexsort((y2d\n",
    "#                                ,weights2d\n",
    "#                                ,X))\n",
    "# idx0 = np.arange(X.shape[0]).reshape(-1, 1)\n",
    "# # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "# s_w, s_f, s_y = weights2d[idx0, sorting_indecies], X[idx0, sorting_indecies], y2d[idx0, sorting_indecies]\n",
    "\n",
    "# for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "#     # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "#     left_weights = np.c_[np.zeros((s_w.shape[0], 1))\n",
    "#                          , np.cumsum(s_w * (s_y == left), axis=1)]\n",
    "#     right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right), axis = 1), axis=1), axis=1)\n",
    "#     # right_weights = np.concatenate((right_weights, [0]))\n",
    "#     right_weights = np.c_[right_weights, np.zeros((right_weights.shape[0], 1))]\n",
    "#     idx = np.argmin(left_weights + right_weights, axis=1)\n",
    "#     # should it be zero???\n",
    "#     idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "#     # if idx >= len(s_f):\n",
    "#     #     idx = len(s_f) - 1\n",
    "#     ii1 = np.arange(idx.shape[0])\n",
    "#     cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "#     temp_bool = cur_min_error < min_error\n",
    "#     min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "#     selected_idx = idx[temp_bool]\n",
    "#     selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "#     best_feature[temp_bool] = np.array(list(zip(selected_idx, selected_features)))\n",
    "#     best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "#     best_polarity[temp_bool] = left\n",
    "#     # if cur_min_error < min_error:\n",
    "#     #     min_error = cur_min_error\n",
    "#     #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "#     #     best_polarity = left\n",
    "# classifiers3 = [WeakClassifier(*clf3) for clf3 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "# # clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "# # classifiers3.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "# print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_features = 16000\n",
    "# n_samples = 15000\n",
    "# n_features = 3\n",
    "# n_samples = 10\n",
    "# n_classes = 2\n",
    "\n",
    "# X = torch.rand(n_features, n_samples, device=device)\n",
    "# y = torch.randint(0, n_classes, (n_samples, ))\n",
    "# y = torch.tensor([1 if i == 1 else -1 for i in y], device=device)\n",
    "# weights = torch.rand(n_samples, device=device)\n",
    "y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "weights = torch.tensor(weights, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.5654296875 Mb\n",
      "1158.0 Mb\n"
     ]
    }
   ],
   "source": [
    "def mem(idx=None):\n",
    "    if idx:print('At index: ', idx, ': ')\n",
    "    print(torch.cuda.memory_allocated()/(1024**2), 'Mb')\n",
    "    print(torch.cuda.memory_reserved()/(1024**2), 'Mb')\n",
    "mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, n_features=3, n_samples=10):\n",
    "        self.X = torch.rand(n_features, n_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "dataset = FeaturesDataset(n_features=n_features, n_samples=n_samples)\n",
    "dataset.X = torch.tensor(X, dtype=torch.float32)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1000, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index:  0 :  Start time:  1.6864206790924072\n",
      "230.2529296875 Mb\n",
      "1158.0 Mb\n",
      "518.71337890625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  1 :  Start time:  2.5111536979675293\n",
      "At index:  1 : \n",
      "633.17431640625 Mb\n",
      "1158.0 Mb\n",
      "633.19384765625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  2 :  Start time:  2.7511305809020996\n",
      "At index:  2 : \n",
      "633.19384765625 Mb\n",
      "1158.0 Mb\n",
      "633.21337890625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  3 :  Start time:  2.9252548217773438\n",
      "At index:  3 : \n",
      "633.21337890625 Mb\n",
      "1158.0 Mb\n",
      "633.67431640625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  4 :  Start time:  3.098696708679199\n",
      "At index:  4 : \n",
      "633.23291015625 Mb\n",
      "1158.0 Mb\n",
      "634.03173828125 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  5 :  Start time:  3.2732608318328857\n",
      "At index:  5 : \n",
      "634.47412109375 Mb\n",
      "1158.0 Mb\n",
      "633.27294921875 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  6 :  Start time:  3.447366714477539\n",
      "At index:  6 : \n",
      "633.27197265625 Mb\n",
      "1158.0 Mb\n",
      "633.29150390625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  7 :  Start time:  3.621185541152954\n",
      "At index:  7 : \n",
      "633.29150390625 Mb\n",
      "1158.0 Mb\n",
      "633.31103515625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  8 :  Start time:  3.797186851501465\n",
      "At index:  8 : \n",
      "633.31103515625 Mb\n",
      "1158.0 Mb\n",
      "633.33056640625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  9 :  Start time:  3.9720163345336914\n",
      "At index:  9 : \n",
      "633.33056640625 Mb\n",
      "1158.0 Mb\n",
      "633.79150390625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  10 :  Start time:  4.145892381668091\n",
      "At index:  10 : \n",
      "633.35009765625 Mb\n",
      "1158.0 Mb\n",
      "634.14892578125 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  11 :  Start time:  4.322677373886108\n",
      "At index:  11 : \n",
      "634.59033203125 Mb\n",
      "1158.0 Mb\n",
      "633.38916015625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  12 :  Start time:  4.563319683074951\n",
      "At index:  12 : \n",
      "633.38916015625 Mb\n",
      "1158.0 Mb\n",
      "633.40869140625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  13 :  Start time:  4.737321615219116\n",
      "At index:  13 : \n",
      "633.40869140625 Mb\n",
      "1158.0 Mb\n",
      "633.42822265625 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  14 :  Start time:  4.911839723587036\n",
      "At index:  14 : \n",
      "633.42919921875 Mb\n",
      "1158.0 Mb\n",
      "633.44873046875 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "At index:  15 :  Start time:  5.0850160121917725\n",
      "At index:  15 : \n",
      "633.44873046875 Mb\n",
      "1158.0 Mb\n",
      "633.90966796875 Mb\n",
      "1158.0 Mb\n",
      "torch.Size([1000, 15000])\n",
      "torch.Size([1000, 15000])\n",
      "Time taken: 5.297734 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_t = time.time()\n",
    "\n",
    "classifiers4 = []\n",
    "total_features4 = n_features\n",
    "\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "# for index, feature in enumerate(X):\n",
    "#     if len(classifiers4) % 1000 == 0 and len(classifiers4) != 0:\n",
    "#         print(\"Trained %d classifiers out of %d\" % (len(classifiers4), total_features4))\n",
    "        \n",
    "for index, X in enumerate(dataloader):\n",
    "\n",
    "    print('At index: ', index, ':', ' Start time: ', time.time() - s_t)\n",
    "    X = X.to(device)\n",
    "    \n",
    "    mem(index)\n",
    "    min_error, best_feature, best_threshold, best_polarity = torch.tensor([float('inf')]*X.shape[0], device=device)\\\n",
    "        , torch.zeros((X.shape[0], 2), device=device), torch.zeros(X.shape[0], device=device), torch.zeros(X.shape[0], device=device)\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "    weights2d = torch.tile(weights, (X.shape[0], 1))\n",
    "    # del weights\n",
    "    y2d = torch.tile(y, (X.shape[0], 1))\n",
    "    # del y\n",
    "    # sorting_indecies = torch.lexsort((y2d\n",
    "    #                             ,weights2d\n",
    "    #                             ,X)).to(device)\n",
    "    sorting_indecies = torch.argsort(X,stable=True) \n",
    "    idx0 = torch.arange(X.shape[0]).reshape(-1, 1).to(device)\n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w = weights2d[idx0, sorting_indecies]\n",
    "    # del weights2d\n",
    "    s_f = X[idx0, sorting_indecies]\n",
    "    # del X\n",
    "    s_y = y2d[idx0, sorting_indecies]\n",
    "    # del y2d\n",
    "    # del idx0\n",
    "    \n",
    "    mem()\n",
    "\n",
    "\n",
    "    for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "        print(s_w.shape)\n",
    "        # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "        left_weights = torch.cat((torch.zeros((s_w.shape[0], 1), device=device)\n",
    "                            , torch.cumsum(s_w * (s_y == left), axis=1)), axis=1)\n",
    "        right_weights = torch.flip(torch.cumsum(torch.flip(s_w * (s_y == right), dims = [1]), axis=1), dims=[1])\n",
    "        # right_weights = np.concatenate((right_weights, [0]))\n",
    "        right_weights = torch.cat((right_weights, torch.zeros((right_weights.shape[0], 1), device=device)), axis=1)\n",
    "        idx = torch.argmin(left_weights + right_weights, axis=1)\n",
    "        # should it be zero???\n",
    "        idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "        # if idx >= len(s_f):\n",
    "        #     idx = len(s_f) - 1\n",
    "        ii1 = torch.arange(idx.shape[0], device=device)\n",
    "        cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "        temp_bool = cur_min_error < min_error\n",
    "        min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "        selected_idx = idx[temp_bool]\n",
    "        selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "        best_feature[temp_bool] = torch.tensor(list(zip(selected_idx, selected_features)), device=device)\n",
    "        best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "        best_polarity[temp_bool] = left\n",
    "        # if cur_min_error < min_error:\n",
    "        #     min_error = cur_min_error\n",
    "        #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "        #     best_polarity = left\n",
    "    # add to classifiers4, converted to numpy\n",
    "    classifiers4.extend([WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)])\n",
    "    # classifiers4 = [WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "    # clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    # classifiers3.append(clf2)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in classifiers:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers2:\n",
    "    print(el)\n",
    "print()\n",
    "# for el in classifiers3:\n",
    "#     print(el)\n",
    "# print()\n",
    "\n",
    "for el in classifiers4:\n",
    "    print(el)\n",
    "print()\n",
    "\n",
    "# classifiers==classifiers2\n",
    "# print(classifiers[0])\n",
    "# print(classifiers2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.18940000e+04  8.26430887e-01  8.26430887e-01 -1.00000000e+00\n",
      " -1.09595765e+02]\n",
      "[ 1.18940000e+04  8.26430887e-01  8.26430887e-01  1.00000000e+00\n",
      " -1.09595765e+02]\n",
      "[ 1.189400e+04  8.264309e-01  8.264309e-01  1.000000e+00 -1.095957e+02]\n",
      "\n",
      "[ 1.32820000e+04  1.22832837e+00  1.22832837e+00 -1.00000000e+00\n",
      " -1.80398181e+02]\n",
      "[ 1.32820000e+04  1.22832837e+00  1.22832837e+00 -1.00000000e+00\n",
      " -1.80398181e+02]\n",
      "[ 1.3282000e+04  1.2283283e+00  1.2283283e+00 -1.0000000e+00\n",
      " -1.8039819e+02]\n",
      "\n",
      "[ 9.62400000e+03  3.70040043e-01  3.70040043e-01  1.00000000e+00\n",
      " -1.43018376e+02]\n",
      "[ 9.62400000e+03  3.70040043e-01  3.70040043e-01 -1.00000000e+00\n",
      " -1.43018376e+02]\n",
      "[ 9.6240000e+03  3.7004003e-01  3.7004003e-01 -1.0000000e+00\n",
      " -1.4301843e+02]\n",
      "\n",
      "[ 4.36400000e+03 -5.45239215e-01 -5.45239215e-01 -1.00000000e+00\n",
      " -1.44850560e+02]\n",
      "[ 4.36400000e+03 -5.45239215e-01 -5.45239215e-01  1.00000000e+00\n",
      " -1.44850560e+02]\n",
      "[ 4.364000e+03 -5.452392e-01 -5.452392e-01  1.000000e+00 -1.448506e+02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(classifiers[i])\n",
    "    print(classifiers2[i])\n",
    "    print(classifiers4[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -2.07043852]\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292 -1.         -2.07043852]]\n",
      "\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292  1.         -2.07043852]]\n",
      "\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292  1.         -2.07043852]]\n",
      "[]\n",
      "[[2 3]\n",
      " [2 4]]\n",
      "[ 1.         -2.07043852]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.zeros((len(classifiers), 5))\n",
    "for i in range(len(classifiers)):\n",
    "    a1[i] = np.array(classifiers[i])\n",
    "\n",
    "a2 = np.zeros((len(classifiers2), 5))\n",
    "for i in range(len(classifiers2)):\n",
    "    a2[i] = np.array(classifiers2[i])\n",
    "a3 = np.zeros((len(classifiers3), 5))\n",
    "for i in range(len(classifiers3)):\n",
    "    a3[i] = np.array(classifiers3[i])\n",
    "    \n",
    "print(a1[a1!=a2])\n",
    "print(a1)\n",
    "print()\n",
    "print(a2)\n",
    "print()\n",
    "print(a3)\n",
    "print(np.argwhere(a2!=a3))\n",
    "print(np.argwhere(a2!=a1))\n",
    "print(a2[a1!=a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
