{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 16000\n",
    "n_samples = 15000\n",
    "# n_features = 3\n",
    "# n_samples = 10\n",
    "n_classes = 2\n",
    "X = np.random.randn(n_features, n_samples)\n",
    "y = np.random.randint(0, n_classes, n_samples)\n",
    "y = np.array([1 if i == 1 else -1 for i in y])\n",
    "weights = np.random.randn(n_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "    def __init__(self, feature_index, feature_val, threshold, polarity, error):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.error = error\n",
    "    \n",
    "    # make a function for easier access as numpy array, example: np.array(wc)\n",
    "    def __array__(self):\n",
    "        return np.array([self.feature_index, self.feature_val, self.threshold, self.polarity, self.error])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return np.array(self).__str__()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1000 classifiers out of 16000\n",
      "Trained 2000 classifiers out of 16000\n",
      "Trained 3000 classifiers out of 16000\n",
      "Trained 4000 classifiers out of 16000\n",
      "Trained 5000 classifiers out of 16000\n",
      "Trained 6000 classifiers out of 16000\n",
      "Trained 7000 classifiers out of 16000\n",
      "Trained 8000 classifiers out of 16000\n",
      "Trained 9000 classifiers out of 16000\n",
      "Trained 10000 classifiers out of 16000\n",
      "Trained 11000 classifiers out of 16000\n",
      "Trained 12000 classifiers out of 16000\n",
      "Trained 13000 classifiers out of 16000\n",
      "Trained 14000 classifiers out of 16000\n",
      "Trained 15000 classifiers out of 16000\n",
      "Time taken: 348.600005 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "\n",
    "total_pos, total_neg = 0, 0\n",
    "for w, label in zip(weights, y):\n",
    "    if label == 1:\n",
    "        total_pos += w\n",
    "    else:\n",
    "        total_neg += w\n",
    "\n",
    "classifiers = []\n",
    "total_features = X.shape[0]\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "    applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "    pos_seen, neg_seen = 0, 0\n",
    "    pos_weights, neg_weights = 0, 0\n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "    current_idx = 0\n",
    "    ws = []\n",
    "    last_error = 0\n",
    "    pos_seen_list = []\n",
    "    for w, f, label in applied_feature:\n",
    "        ws.append(w)\n",
    "        # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "        # error = sum of weights of misclassified examples\n",
    "        error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "        last_error = error\n",
    "        # print(\"error : \", error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            # best_feature = features[index]\n",
    "            best_feature = (current_idx, f)\n",
    "            best_threshold = f\n",
    "            best_polarity = 1 if pos_seen > neg_seen else -1\n",
    "\n",
    "        if label == 1:\n",
    "            pos_seen += 1\n",
    "            pos_weights += w\n",
    "        else:\n",
    "            neg_seen += 1\n",
    "            neg_weights += w\n",
    "        current_idx += 1\n",
    "        pos_seen_list.append(pos_seen)\n",
    "\n",
    "    # clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity)\n",
    "    clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine\n",
    "\n",
    "<h3>\n",
    "<div style='color: red;'>\n",
    "Question: for the polarity:<br>\n",
    " Direction that gives minimum weights <span style='color:pink'> -> To be consistent with finding minimum error using weights</span><br> \n",
    "    or<br>\n",
    " Direction that gives less misclassified samples???? <span style='color:pink'> -> To find threshold giving better accuracy???</span></div>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1000 classifiers out of 16000\n",
      "Trained 2000 classifiers out of 16000\n",
      "Trained 3000 classifiers out of 16000\n",
      "Trained 4000 classifiers out of 16000\n",
      "Trained 5000 classifiers out of 16000\n",
      "Trained 6000 classifiers out of 16000\n",
      "Trained 7000 classifiers out of 16000\n",
      "Trained 8000 classifiers out of 16000\n",
      "Trained 9000 classifiers out of 16000\n",
      "Trained 10000 classifiers out of 16000\n",
      "Trained 11000 classifiers out of 16000\n",
      "Trained 12000 classifiers out of 16000\n",
      "Trained 13000 classifiers out of 16000\n",
      "Trained 14000 classifiers out of 16000\n",
      "Trained 15000 classifiers out of 16000\n",
      "Time taken: 38.363074 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "classifiers2 = []\n",
    "total_features2 = X.shape[0]\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers2) % 1000 == 0 and len(classifiers2) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers2), total_features2))\n",
    "        \n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok?\n",
    "    sorting_indecies = np.lexsort((y, weights, feature))\n",
    "    \n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w, s_f, s_y = weights[sorting_indecies], feature[sorting_indecies], y[sorting_indecies]\n",
    "    \n",
    "    for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "        left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left))))\n",
    "        right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right))))\n",
    "        right_weights = np.concatenate((right_weights, [0]))\n",
    "        idx = np.argmin(left_weights + right_weights)\n",
    "        if idx >= len(s_f):\n",
    "            idx = len(s_f) - 1\n",
    "            \n",
    "        cur_min_error = left_weights[idx] + right_weights[idx]\n",
    "        if cur_min_error < min_error:\n",
    "            min_error = cur_min_error\n",
    "            best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "            best_polarity = left\n",
    "\n",
    "    clf2 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers2.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more optimized?\n",
    "<h1>\n",
    "    <div style='color:red'>\n",
    "        Unfortunately, didn't work. The computer freezes when I try to run it.\n",
    "    </div>\n",
    "    <div style='color:red'>\n",
    "        Maybe will need to run it on a GPU??\n",
    "    </div>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t = time.time()\n",
    "classifiers3 = []\n",
    "total_features3 = X.shape[0]\n",
    "\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "# for index, feature in enumerate(X):\n",
    "#     if len(classifiers3) % 1000 == 0 and len(classifiers3) != 0:\n",
    "#         print(\"Trained %d classifiers out of %d\" % (len(classifiers3), total_features3))\n",
    "        \n",
    "\n",
    "min_error, best_feature, best_threshold, best_polarity = np.array([float('inf')]*X.shape[0])\\\n",
    "    , np.zeros((X.shape[0], 2)), np.zeros(X.shape[0]), np.zeros(X.shape[0])\n",
    "\n",
    "# sort by feature value first, then by weight, then by label\n",
    "# TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "weights2d = np.tile(weights, (X.shape[0], 1))\n",
    "y2d = np.tile(y, (X.shape[0], 1))\n",
    "sorting_indecies = np.lexsort((y2d\n",
    "                               ,weights2d\n",
    "                               ,X))\n",
    "idx0 = np.arange(X.shape[0]).reshape(-1, 1)\n",
    "# s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "s_w, s_f, s_y = weights2d[idx0, sorting_indecies], X[idx0, sorting_indecies], y2d[idx0, sorting_indecies]\n",
    "\n",
    "for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "    # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "    left_weights = np.c_[np.zeros((s_w.shape[0], 1))\n",
    "                         , np.cumsum(s_w * (s_y == left), axis=1)]\n",
    "    right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right), axis = 1), axis=1), axis=1)\n",
    "    # right_weights = np.concatenate((right_weights, [0]))\n",
    "    right_weights = np.c_[right_weights, np.zeros((right_weights.shape[0], 1))]\n",
    "    idx = np.argmin(left_weights + right_weights, axis=1)\n",
    "    # should it be zero???\n",
    "    idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "    # if idx >= len(s_f):\n",
    "    #     idx = len(s_f) - 1\n",
    "    ii1 = np.arange(idx.shape[0])\n",
    "    cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "    temp_bool = cur_min_error < min_error\n",
    "    min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "    selected_idx = idx[temp_bool]\n",
    "    selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "    best_feature[temp_bool] = np.array(list(zip(selected_idx, selected_features)))\n",
    "    best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "    best_polarity[temp_bool] = left\n",
    "    # if cur_min_error < min_error:\n",
    "    #     min_error = cur_min_error\n",
    "    #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "    #     best_polarity = left\n",
    "classifiers3 = [WeakClassifier(*clf3) for clf3 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "# clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "# classifiers3.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.          0.33365897  0.33365897  1.         -2.58596895]\n",
      "[ 6.          0.83123379  0.83123379 -1.         -4.38605707]\n",
      "[ 5.         -0.17706    -0.17706     1.         -1.82290006]\n",
      "\n",
      "[ 7.          0.33365897  0.33365897 -1.         -2.58596895]\n",
      "[ 6.          0.83123379  0.83123379  1.         -4.38605707]\n",
      "[ 5.         -0.17706    -0.17706     1.         -1.82290006]\n",
      "\n",
      "[ 7.          0.33365897  0.33365897 -1.         -2.58596895]\n",
      "[ 6.          0.83123379  0.83123379  1.         -4.38605707]\n",
      "[ 5.         -0.17706    -0.17706     1.         -1.82290006]\n"
     ]
    }
   ],
   "source": [
    "for el in classifiers:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers2:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers3:\n",
    "    print(el)\n",
    "# classifiers==classifiers2\n",
    "# print(classifiers[0])\n",
    "# print(classifiers2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.         -1.         -4.38605707 -1.82290006]\n",
      "[[ 7.          0.33365897  0.33365897  1.         -2.58596895]\n",
      " [ 6.          0.83123379  0.83123379 -1.         -4.38605707]\n",
      " [ 5.         -0.17706    -0.17706     1.         -1.82290006]]\n",
      "\n",
      "[[ 7.          0.33365897  0.33365897 -1.         -2.58596895]\n",
      " [ 6.          0.83123379  0.83123379  1.         -4.38605707]\n",
      " [ 5.         -0.17706    -0.17706     1.         -1.82290006]]\n",
      "\n",
      "[[ 7.          0.33365897  0.33365897 -1.         -2.58596895]\n",
      " [ 6.          0.83123379  0.83123379  1.         -4.38605707]\n",
      " [ 5.         -0.17706    -0.17706     1.         -1.82290006]]\n",
      "[]\n",
      "[[0 3]\n",
      " [1 3]\n",
      " [1 4]\n",
      " [2 4]]\n",
      "[-1.          1.         -4.38605707 -1.82290006]\n",
      "-4.38605706517018 -4.386057065170179 -4.386057065170179\n",
      "-1.8229000640981816 -1.8229000640981814 -1.8229000640981814\n"
     ]
    }
   ],
   "source": [
    "a1 = np.zeros((len(classifiers), 5))\n",
    "for i in range(len(classifiers)):\n",
    "    a1[i] = np.array(classifiers[i])\n",
    "\n",
    "a2 = np.zeros((len(classifiers2), 5))\n",
    "for i in range(len(classifiers2)):\n",
    "    a2[i] = np.array(classifiers2[i])\n",
    "a3 = np.zeros((len(classifiers3), 5))\n",
    "for i in range(len(classifiers3)):\n",
    "    a3[i] = np.array(classifiers3[i])\n",
    "    \n",
    "print(a1[a1!=a2])\n",
    "print(a1)\n",
    "print()\n",
    "print(a2)\n",
    "print()\n",
    "print(a3)\n",
    "print(np.argwhere(a2!=a3))\n",
    "print(np.argwhere(a2!=a1))\n",
    "print(a2[a1!=a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
