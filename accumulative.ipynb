{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakClassifier:\n",
    "    def __init__(self, feature_index, feature_val, threshold, polarity, error):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.error = error\n",
    "    \n",
    "    # make a function for easier access as numpy array, example: np.array(wc)\n",
    "    def __array__(self):\n",
    "        # return tensor.cpu() if members are tensors else np.array\n",
    "        if type(self.feature_index) == torch.Tensor:\n",
    "            return np.array([self.feature_index.cpu().numpy(), self.feature_val.cpu().numpy(), self.threshold.cpu().numpy(), self.polarity.cpu().numpy(), self.error.cpu().numpy()])\n",
    "        else:\n",
    "            return np.array([self.feature_index, self.feature_val, self.threshold, self.polarity, self.error])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return np.array(self).__str__()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# np init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_features = 16000\n",
    "# n_samples = 15000\n",
    "n_features = 3\n",
    "n_samples = 10\n",
    "n_classes = 2\n",
    "X = np.random.randn(n_features, n_samples)\n",
    "y = np.random.randint(0, n_classes, n_samples)\n",
    "y = np.array([1 if i == 1 else -1 for i in y])\n",
    "weights = np.random.randn(n_samples)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Their method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.000632 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "\n",
    "total_pos, total_neg = 0, 0\n",
    "for w, label in zip(weights, y):\n",
    "    if label == 1:\n",
    "        total_pos += w\n",
    "    else:\n",
    "        total_neg += w\n",
    "\n",
    "classifiers = []\n",
    "total_features = X.shape[0]\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "    applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "    pos_seen, neg_seen = 0, 0\n",
    "    pos_weights, neg_weights = 0, 0\n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "    current_idx = 0\n",
    "    ws = []\n",
    "    last_error = 0\n",
    "    pos_seen_list = []\n",
    "    for w, f, label in applied_feature:\n",
    "        ws.append(w)\n",
    "        # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "        # error = sum of weights of misclassified examples\n",
    "        error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "        last_error = error\n",
    "        # print(\"error : \", error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            # best_feature = features[index]\n",
    "            best_feature = (current_idx, f)\n",
    "            best_threshold = f\n",
    "            best_polarity = 1 if pos_seen > neg_seen else -1\n",
    "\n",
    "        if label == 1:\n",
    "            pos_seen += 1\n",
    "            pos_weights += w\n",
    "        else:\n",
    "            neg_seen += 1\n",
    "            neg_weights += w\n",
    "        current_idx += 1\n",
    "        pos_seen_list.append(pos_seen)\n",
    "\n",
    "    # clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity)\n",
    "    clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mine\n",
    "\n",
    "<h3>\n",
    "<div style='color: red;'>\n",
    "Question: for the polarity:<br>\n",
    " Direction that gives minimum weights <span style='color:pink'> -> To be consistent with finding minimum error using weights</span><br> \n",
    "    or<br>\n",
    " Direction that gives less misclassified samples???? <span style='color:pink'> -> To find threshold giving better accuracy???</span></div>\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.000776 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "classifiers2 = []\n",
    "total_features2 = X.shape[0]\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers2) % 1000 == 0 and len(classifiers2) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers2), total_features2))\n",
    "        \n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok?\n",
    "    sorting_indecies = np.lexsort((y, weights, feature))\n",
    "    \n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w, s_f, s_y = weights[sorting_indecies], feature[sorting_indecies], y[sorting_indecies]\n",
    "    \n",
    "    for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "        left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left))))\n",
    "        right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right))))\n",
    "        right_weights = np.concatenate((right_weights, [0]))\n",
    "        idx = np.argmin(left_weights + right_weights)\n",
    "        if idx >= len(s_f):\n",
    "            idx = len(s_f) - 1\n",
    "            \n",
    "        cur_min_error = left_weights[idx] + right_weights[idx]\n",
    "        if cur_min_error < min_error:\n",
    "            min_error = cur_min_error\n",
    "            best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "            best_polarity = left\n",
    "\n",
    "    clf2 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    classifiers2.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Even more optimized?\n",
    "<h1>\n",
    "    <div style='color:red'>\n",
    "        Unfortunately, didn't work. The computer freezes when I try to run it.\n",
    "    </div>\n",
    "    <div style='color:red'>\n",
    "        Maybe will need to run it on a GPU??\n",
    "    </div>\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.004261 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "classifiers3 = []\n",
    "total_features3 = X.shape[0]\n",
    "\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "# for index, feature in enumerate(X):\n",
    "#     if len(classifiers3) % 1000 == 0 and len(classifiers3) != 0:\n",
    "#         print(\"Trained %d classifiers out of %d\" % (len(classifiers3), total_features3))\n",
    "        \n",
    "\n",
    "min_error, best_feature, best_threshold, best_polarity = np.array([float('inf')]*X.shape[0])\\\n",
    "    , np.zeros((X.shape[0], 2)), np.zeros(X.shape[0]), np.zeros(X.shape[0])\n",
    "\n",
    "# sort by feature value first, then by weight, then by label\n",
    "# TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "weights2d = np.tile(weights, (X.shape[0], 1))\n",
    "y2d = np.tile(y, (X.shape[0], 1))\n",
    "sorting_indecies = np.lexsort((y2d\n",
    "                               ,weights2d\n",
    "                               ,X))\n",
    "idx0 = np.arange(X.shape[0]).reshape(-1, 1)\n",
    "# s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "s_w, s_f, s_y = weights2d[idx0, sorting_indecies], X[idx0, sorting_indecies], y2d[idx0, sorting_indecies]\n",
    "\n",
    "for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "    # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "    left_weights = np.c_[np.zeros((s_w.shape[0], 1))\n",
    "                         , np.cumsum(s_w * (s_y == left), axis=1)]\n",
    "    right_weights = np.flip(np.cumsum(np.flip(s_w * (s_y == right), axis = 1), axis=1), axis=1)\n",
    "    # right_weights = np.concatenate((right_weights, [0]))\n",
    "    right_weights = np.c_[right_weights, np.zeros((right_weights.shape[0], 1))]\n",
    "    idx = np.argmin(left_weights + right_weights, axis=1)\n",
    "    # should it be zero???\n",
    "    idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "    # if idx >= len(s_f):\n",
    "    #     idx = len(s_f) - 1\n",
    "    ii1 = np.arange(idx.shape[0])\n",
    "    cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "    temp_bool = cur_min_error < min_error\n",
    "    min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "    selected_idx = idx[temp_bool]\n",
    "    selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "    best_feature[temp_bool] = np.array(list(zip(selected_idx, selected_features)))\n",
    "    best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "    best_polarity[temp_bool] = left\n",
    "    # if cur_min_error < min_error:\n",
    "    #     min_error = cur_min_error\n",
    "    #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "    #     best_polarity = left\n",
    "classifiers3 = [WeakClassifier(*clf3) for clf3 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "# clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "# classifiers3.append(clf2)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# n_features = 16000\n",
    "# n_samples = 15000\n",
    "n_features = 3\n",
    "n_samples = 10\n",
    "n_classes = 2\n",
    "\n",
    "# X = torch.rand(n_features, n_samples, device=device)\n",
    "# y = torch.randint(0, n_classes, (n_samples, ))\n",
    "# y = torch.tensor([1 if i == 1 else -1 for i in y], device=device)\n",
    "# weights = torch.rand(n_samples, device=device)\n",
    "y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "weights = torch.tensor(weights, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0068359375 Mb\n",
      "2.0 Mb\n"
     ]
    }
   ],
   "source": [
    "def mem(idx=None):\n",
    "    if idx:print('At index: ', idx, ': ')\n",
    "    print(torch.cuda.memory_allocated()/(1024**2), 'Mb')\n",
    "    print(torch.cuda.memory_reserved()/(1024**2), 'Mb')\n",
    "mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self, n_features=3, n_samples=10):\n",
    "        self.X = torch.rand(n_features, n_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "dataset = FeaturesDataset(n_features=n_features, n_samples=n_samples)\n",
    "dataset.X = torch.tensor(X, dtype=torch.float32)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1000, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At index:  0 :  Start time:  0.060237884521484375\n",
      "0.00732421875 Mb\n",
      "2.0 Mb\n",
      "0.0126953125 Mb\n",
      "2.0 Mb\n",
      "torch.Size([3, 10])\n",
      "torch.Size([3, 10])\n",
      "Time taken: 0.088962 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s_t = time.time()\n",
    "\n",
    "classifiers4 = []\n",
    "total_features4 = n_features\n",
    "\n",
    "# TODO parallize this\n",
    "# TODO can we get rid of this loop and make them matrices?\n",
    "# for index, feature in enumerate(X):\n",
    "#     if len(classifiers4) % 1000 == 0 and len(classifiers4) != 0:\n",
    "#         print(\"Trained %d classifiers out of %d\" % (len(classifiers4), total_features4))\n",
    "        \n",
    "for index, X in enumerate(dataloader):\n",
    "\n",
    "    print('At index: ', index, ':', ' Start time: ', time.time() - s_t)\n",
    "    X = X.to(device)\n",
    "    \n",
    "    mem(index)\n",
    "    min_error, best_feature, best_threshold, best_polarity = torch.tensor([float('inf')]*X.shape[0], device=device)\\\n",
    "        , torch.zeros((X.shape[0], 2), device=device), torch.zeros(X.shape[0], device=device), torch.zeros(X.shape[0], device=device)\n",
    "\n",
    "    # sort by feature value first, then by weight, then by label\n",
    "    # TODO No need for lexsort, and argsort is ok? looks like tile is expensive\n",
    "    weights2d = torch.tile(weights, (X.shape[0], 1))\n",
    "    # del weights\n",
    "    y2d = torch.tile(y, (X.shape[0], 1))\n",
    "    # del y\n",
    "    # sorting_indecies = torch.lexsort((y2d\n",
    "    #                             ,weights2d\n",
    "    #                             ,X)).to(device)\n",
    "    sorting_indecies = torch.argsort(X,stable=True) \n",
    "    idx0 = torch.arange(X.shape[0]).reshape(-1, 1).to(device)\n",
    "    # s_w: srorted weights, s_f: sorted features, s_y: sorted labels\n",
    "    s_w = weights2d[idx0, sorting_indecies]\n",
    "    # del weights2d\n",
    "    s_f = X[idx0, sorting_indecies]\n",
    "    # del X\n",
    "    s_y = y2d[idx0, sorting_indecies]\n",
    "    # del y2d\n",
    "    # del idx0\n",
    "    \n",
    "    mem()\n",
    "\n",
    "\n",
    "    for left, right in [(-1, 1), (1, -1)]: #@ y: -1 or 1\n",
    "        print(s_w.shape)\n",
    "        # left_weights = np.concatenate(([0], np.cumsum(s_w * (s_y == left), axis=1)))\n",
    "        left_weights = torch.cat((torch.zeros((s_w.shape[0], 1), device=device)\n",
    "                            , torch.cumsum(s_w * (s_y == left), axis=1)), axis=1)\n",
    "        right_weights = torch.flip(torch.cumsum(torch.flip(s_w * (s_y == right), dims = [1]), axis=1), dims=[1])\n",
    "        # right_weights = np.concatenate((right_weights, [0]))\n",
    "        right_weights = torch.cat((right_weights, torch.zeros((right_weights.shape[0], 1), device=device)), axis=1)\n",
    "        idx = torch.argmin(left_weights + right_weights, axis=1)\n",
    "        # should it be zero???\n",
    "        idx[idx >= s_f.shape[1]] = s_f.shape[1] - 1\n",
    "        # if idx >= len(s_f):\n",
    "        #     idx = len(s_f) - 1\n",
    "        ii1 = torch.arange(idx.shape[0], device=device)\n",
    "        cur_min_error = left_weights[ii1, idx] + right_weights[ii1, idx]\n",
    "        temp_bool = cur_min_error < min_error\n",
    "        min_error[temp_bool] = cur_min_error[temp_bool]\n",
    "        selected_idx = idx[temp_bool]\n",
    "        selected_features = s_f[ii1[temp_bool], selected_idx]\n",
    "        best_feature[temp_bool] = torch.tensor(list(zip(selected_idx, selected_features)), device=device)\n",
    "        best_threshold[temp_bool] = s_f[ii1[temp_bool], idx[temp_bool]]\n",
    "        best_polarity[temp_bool] = left\n",
    "        # if cur_min_error < min_error:\n",
    "        #     min_error = cur_min_error\n",
    "        #     best_feature, best_threshold = (idx, s_f[idx]), s_f[idx]\n",
    "        #     best_polarity = left\n",
    "    # add to classifiers4, converted to numpy\n",
    "    classifiers4.extend([WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)])\n",
    "    # classifiers4 = [WeakClassifier(*clf4) for clf4 in zip(best_feature[:,0], best_feature[:,1], best_threshold, best_polarity, min_error)]\n",
    "    # clf3 = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "    # classifiers3.append(clf2)\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      "[ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      "[ 9.          1.17385292  1.17385292 -1.         -2.07043852]\n",
      "\n",
      "[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      "[ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      "[ 9.          1.17385292  1.17385292  1.         -2.07043852]\n",
      "\n",
      "[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      "[ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      "[ 9.          1.17385292  1.17385292  1.         -2.07043852]\n",
      "\n",
      "[ 7.         0.8002729  0.8002729 -1.        -0.9754143]\n",
      "[ 2.          0.15299952  0.15299952 -1.         -3.0871985 ]\n",
      "[ 9.         1.1738529  1.1738529  1.        -2.0704384]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in classifiers:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers2:\n",
    "    print(el)\n",
    "print()\n",
    "for el in classifiers3:\n",
    "    print(el)\n",
    "print()\n",
    "\n",
    "for el in classifiers4:\n",
    "    print(el)\n",
    "print()\n",
    "\n",
    "# classifiers==classifiers2\n",
    "# print(classifiers[0])\n",
    "# print(classifiers2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.         -2.07043852]\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292 -1.         -2.07043852]]\n",
      "\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292  1.         -2.07043852]]\n",
      "\n",
      "[[ 7.          0.80027287  0.80027287 -1.         -0.97541437]\n",
      " [ 2.          0.15299952  0.15299952 -1.         -3.08719862]\n",
      " [ 9.          1.17385292  1.17385292  1.         -2.07043852]]\n",
      "[]\n",
      "[[2 3]\n",
      " [2 4]]\n",
      "[ 1.         -2.07043852]\n"
     ]
    }
   ],
   "source": [
    "a1 = np.zeros((len(classifiers), 5))\n",
    "for i in range(len(classifiers)):\n",
    "    a1[i] = np.array(classifiers[i])\n",
    "\n",
    "a2 = np.zeros((len(classifiers2), 5))\n",
    "for i in range(len(classifiers2)):\n",
    "    a2[i] = np.array(classifiers2[i])\n",
    "a3 = np.zeros((len(classifiers3), 5))\n",
    "for i in range(len(classifiers3)):\n",
    "    a3[i] = np.array(classifiers3[i])\n",
    "    \n",
    "print(a1[a1!=a2])\n",
    "print(a1)\n",
    "print()\n",
    "print(a2)\n",
    "print()\n",
    "print(a3)\n",
    "print(np.argwhere(a2!=a3))\n",
    "print(np.argwhere(a2!=a1))\n",
    "print(a2[a1!=a2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
