{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook tests choosing the best classifier. It compares its output with another implmentation of the same algorithm.: aparande\n",
    "### also, it ensures that the best error chosen is the same on the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from classifier import BestClassifier, WeakClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EQ(x, y, permittivity=1e-6):\n",
    "    return np.abs(x - y) < permittivity\n",
    "def EQ3(x, y, z, permittivity=1e-4):\n",
    "    return EQ(x, y, permittivity) and EQ(y, z, permittivity)\n",
    "def OK(msg='OK'):\n",
    "    print(\"\\033[32m{}\\033[0m\".format(msg))\n",
    "def NOK(msg='Not Equal'):\n",
    "    print(\"\\033[31m{}\\033[0m\".format(msg))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheirWeakClassifier:\n",
    "    def __init__(self, feature_index, feature_val, threshold, polarity, error):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "        self.error = error\n",
    "    \n",
    "    # make a function for easier access as numpy array, example: np.array(wc)\n",
    "    def __array__(self):\n",
    "        # return tensor.cpu() if members are tensors else np.array\n",
    "        if type(self.feature_index) == torch.Tensor:\n",
    "            return np.array([self.feature_index.cpu().numpy(), self.feature_val.cpu().numpy(), self.threshold.cpu().numpy(), self.polarity.cpu().numpy(), self.error.cpu().numpy()])\n",
    "        else:\n",
    "            return np.array([self.feature_index, self.feature_val, self.threshold, self.polarity, self.error])\n",
    "        \n",
    "    def __str__(self):\n",
    "        return np.array(self).__str__()\n",
    "    \n",
    "def train_weak(X, y, features, weights):\n",
    "    s_t = time.time()\n",
    "\n",
    "    total_pos, total_neg = 0, 0\n",
    "    for w, label in zip(weights, y):\n",
    "        if label == 1:\n",
    "            total_pos += w\n",
    "        else:\n",
    "            total_neg += w\n",
    "\n",
    "    classifiers = []\n",
    "    total_features = X.shape[0]\n",
    "    for index, feature in enumerate(X):\n",
    "        if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "            print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "        applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "        pos_seen, neg_seen = 0, 0\n",
    "        pos_weights, neg_weights = 0, 0\n",
    "        min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "        current_idx = 0\n",
    "        ws = []\n",
    "        last_error = 0\n",
    "        pos_seen_list = []\n",
    "        for w, f, label in applied_feature:\n",
    "            ws.append(w)\n",
    "            # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "            # error = sum of weights of misclassified examples\n",
    "            error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "            last_error = error\n",
    "            # print(\"error : \", error)\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                best_feature = (current_idx, f)\n",
    "                best_threshold = f - 0.00001\n",
    "                if neg_weights + total_pos - pos_weights < pos_weights + total_neg - neg_weights:\n",
    "                    best_polarity = 1\n",
    "                else:\n",
    "                    best_polarity = -1\n",
    "\n",
    "\n",
    "            if label == 1:\n",
    "                pos_seen += 1\n",
    "                pos_weights += w\n",
    "            else:\n",
    "                neg_seen += 1\n",
    "                neg_weights += w\n",
    "            current_idx += 1\n",
    "            pos_seen_list.append(pos_seen)\n",
    "\n",
    "        clf = TheirWeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity, min_error)\n",
    "        classifiers.append(clf)\n",
    "\n",
    "    print(\"Time taken: %f seconds\" % (time.time() - s_t))\n",
    "    return classifiers\n",
    "\n",
    "def select_best(classifiers, weights, X, y):\n",
    "    best_clf, best_error, best_accuracy = None, float('inf'), None\n",
    "    xt = X.T\n",
    "    aaa = []\n",
    "    for i, clf in enumerate(classifiers):\n",
    "        error, accuracy = 0, []\n",
    "        bbb = []\n",
    "        for data, w, yc in zip(xt, weights, y):\n",
    "            classification = 1 if data[i] * clf.polarity <= clf.threshold * clf.polarity else 0\n",
    "            correctness = classification != yc\n",
    "            accuracy.append(correctness)\n",
    "            bbb.append(w * correctness)\n",
    "            error += w * correctness\n",
    "        if error < best_error:\n",
    "            best_clf, best_error, best_accuracy = clf, error, accuracy\n",
    "        aaa.append(bbb)\n",
    "    return best_clf, best_error, best_accuracy, aaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5\n",
    "n_samples = 15\n",
    "n_classes = 2\n",
    "def generate_data(n_features=n_features, n_samples=n_samples, floatornot=True):\n",
    "    X = np.random.randn(n_features, n_samples)\n",
    "    if floatornot:\n",
    "        X = X.astype(np.float32)\n",
    "    y = np.random.randint(0, n_classes, n_samples)\n",
    "    weights = np.random.rand(n_samples)\n",
    "    if floatornot:\n",
    "        weights = weights.astype(np.float32)\n",
    "    weights = weights / np.sum(weights)\n",
    "    return X, y, weights\n",
    "X, y, weights = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"X.npy\", X)\n",
    "# np.save(\"y.npy\", y)\n",
    "# np.save(\"weights.npy\", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.load(\"X.npy\")\n",
    "# y = np.load(\"y.npy\")\n",
    "# weights = np.load(\"weights.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.003658 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "\n",
    "total_pos, total_neg = 0, 0\n",
    "for w, label in zip(weights, y):\n",
    "    if label == 1:\n",
    "        total_pos += w\n",
    "    else:\n",
    "        total_neg += w\n",
    "\n",
    "classifiers = []\n",
    "total_features = X.shape[0]\n",
    "for index, feature in enumerate(X):\n",
    "    if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
    "        print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
    "\n",
    "    applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
    "\n",
    "    pos_seen, neg_seen = 0, 0\n",
    "    pos_weights, neg_weights = 0, 0\n",
    "    min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
    "    current_idx = 0\n",
    "    ws = []\n",
    "    last_error = 0\n",
    "    pos_seen_list = []\n",
    "    for w, f, label in applied_feature:\n",
    "        ws.append(w)\n",
    "        # min(all before current example are positive and all after are negative, all before current example are negative and all after are positive)\n",
    "        # error = sum of weights of misclassified examples\n",
    "        error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
    "        last_error = error\n",
    "        # print(\"error : \", error)\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            # best_feature = features[index]\n",
    "            best_feature = (current_idx, f)\n",
    "            best_threshold = f - 0.00001\n",
    "            # best_polarity = 1 if pos_seen > neg_seen else -1\n",
    "            if neg_weights + total_pos - pos_weights < pos_weights + total_neg - neg_weights:\n",
    "                best_polarity = 1\n",
    "            else:\n",
    "                best_polarity = -1\n",
    "                \n",
    "\n",
    "        if label == 1:\n",
    "            pos_seen += 1\n",
    "            pos_weights += w\n",
    "        else:\n",
    "            neg_seen += 1\n",
    "            neg_weights += w\n",
    "        current_idx += 1\n",
    "        pos_seen_list.append(pos_seen)\n",
    "\n",
    "    clf = WeakClassifier(best_feature[0], best_threshold, best_polarity, min_error)\n",
    "    classifiers.append(clf)\n",
    "\n",
    "print(\"Time taken: %f seconds\" % (time.time() - s_t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalence of the two implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to choose classifier\n",
      "Best classifier: index 0, threshold 1.3954046964645386, polarity -1, error 0.20713873207569122\n",
      "\u001b[32mWeights sum to 1\u001b[0m\n",
      "\u001b[32mPredictions are correct\u001b[0m\n",
      "Finished 0 iterations\n",
      "\u001b[32mBest error is correct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "L = 1\n",
    "for i in range(L):\n",
    "    if L > 1:\n",
    "        X, y, weights = generate_data()\n",
    "    # weak_classifiers = BestClassifier(X, y, weights, 1000, False, False, debug=True, delta=0.00001)\n",
    "    weak_classifiers = BestClassifier(X, y, weights, 1000, False, False, debug=True, delta=0.00001)\n",
    "    # best_index, best_threshold, best_polarity, best_error, classifiers4, LW, RW = weak_classifiers.chooseClassifier()\n",
    "    BC, (classifiers4, LW, RW) = weak_classifiers.chooseClassifier()\n",
    "    best_index, best_threshold, best_polarity, best_error = BC.feature_index, BC.threshold, BC.polarity, BC.error\n",
    "    \n",
    "    if L == 1:\n",
    "        print(f\"Best classifier: index {best_index}, threshold {best_threshold}, polarity {best_polarity}, error {best_error}\")\n",
    "\n",
    "    try:\n",
    "        assert (LW[0] + RW[0] + LW[-1] + RW[-1] - 1 < 0.00001).all(), 'NOT EQUAL'\n",
    "        OK('Weights sum to 1')\n",
    "    except:\n",
    "        NOK('Weights do not sum to 1')\n",
    "        print(LW[0] + RW[0] + LW[-1] + RW[-1])\n",
    "        \n",
    "    \n",
    "    datas = X.T\n",
    "    compared_error = 0\n",
    "    prediction1 = []\n",
    "    for data, w, yc in zip(datas, weights, y):\n",
    "        classification = 1 if data[best_index] * best_polarity <= best_threshold * best_polarity else 0\n",
    "        prediction1.append(classification)\n",
    "        correctness = classification != yc\n",
    "        compared_error += w * correctness\n",
    "        \n",
    "    predictions2 = BC.predict(X)\n",
    "    try:\n",
    "        assert (prediction1 == predictions2).all(), 'NOT EQUAL'\n",
    "        OK('Predictions are correct')\n",
    "    except:\n",
    "        NOK('Predictions are not correct')\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"Finished %d iterations\" % i)\n",
    "    try:\n",
    "        assert abs(compared_error - best_error) < 0.0000001, 'NOT EQUAL'\n",
    "        OK('Best error is correct')\n",
    "    except:\n",
    "        NOK('Best error is not correct')\n",
    "        print(\"Compared error: %f\" % compared_error)\n",
    "        print(\"Best error: %f\" % best_error)\n",
    "        \n",
    "\n",
    "        print(\"Compared error: %f\" % compared_error)\n",
    "\n",
    "        for i, clf in enumerate(classifiers4):\n",
    "            error = 0\n",
    "            for data, w, yc in zip(datas, weights, y):\n",
    "                classification = 1 if data[i] * clf.polarity >= clf.threshold * clf.polarity else 0\n",
    "                correctness = classification != yc\n",
    "                error += w * correctness\n",
    "            print(\"Error: %f\" % error, end=' ')\n",
    "            print(f'Polarity: {clf.polarity}', '--------' if error == best_error else '')\n",
    "\n",
    "        print()\n",
    "        for i, clf in enumerate(classifiers4):\n",
    "            error = 0\n",
    "            for data, w, yc in zip(datas, weights, y):\n",
    "                classification = 1 if data[i] * clf.polarity <= clf.threshold * clf.polarity else 0\n",
    "                # classification = classification if clf.polarity == 1 else 1 - classification\n",
    "                # classification = 1 if data[i]  >= clf.threshold else 0\n",
    "                # correctness = classification == yc\n",
    "                correctness = classification != yc\n",
    "                error += w * correctness\n",
    "            print(\"Error2: %f\" % error, end=' ')\n",
    "            print(f'Polarity: {clf.polarity}','--------' if error == best_error else '')\n",
    "        print()\n",
    "        for i, clf in enumerate(classifiers4):\n",
    "            error = 0\n",
    "            for data, w, yc in zip(datas, weights, y):\n",
    "                classification = 1 if data[i] * clf.polarity >= clf.threshold * clf.polarity else 0\n",
    "                correctness = classification == yc\n",
    "                correctness = classification != yc\n",
    "                error += w * correctness\n",
    "            print(\"Error2: %f\" % error, end=' ')\n",
    "            print(f'Polarity: {clf.polarity}','--------' if error == best_error else '')\n",
    "\n",
    "        print()\n",
    "        for i, clf in enumerate(classifiers4):\n",
    "            error = 0\n",
    "            for data, w, yc in zip(datas, weights, y):\n",
    "                classification = 1 if data[i] * clf.polarity <= clf.threshold * clf.polarity else 0\n",
    "                correctness = classification == yc\n",
    "                correctness = classification != yc\n",
    "                error += w * correctness\n",
    "            print(\"Error2: %f\" % error, end=' ')\n",
    "            print(f'Polarity: {clf.polarity}','--------' if error == best_error else '')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.001384 seconds\n",
      "Best classifier: index 12, threshold 1.3954047100448608, polarity -1, error 0.20713873486965895\n",
      "\u001b[32mBest classifier is correct\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "weak_classifiers2 = train_weak(X, y, None, weights)\n",
    "best_clf2, best_error2, best_accuracy2, aaa2 = select_best(weak_classifiers2, weights, X, y)\n",
    "\n",
    "print(f'Best classifier: index {best_clf2.feature_index}, threshold {best_clf2.threshold}, polarity {best_clf2.polarity}, error {best_error2}')\n",
    "\n",
    "try:\n",
    "    assert EQ(best_error, best_error2), 'ϵ NOT EQUAL'\n",
    "    assert EQ(best_threshold, best_clf2.threshold), 'θ NOT EQUAL'\n",
    "    assert EQ(best_polarity, best_clf2.polarity), 'p NOT EQUAL'\n",
    "    OK('Best classifier is correct')\n",
    "except AssertionError as e:\n",
    "    NOK('Best classifier is not correct')\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classifiers4)):\n",
    "    try:\n",
    "        assert EQ3(classifiers4[i].threshold, weak_classifiers2[i].threshold, classifiers[i].threshold), 'θ NOT EQUAL'\n",
    "        assert EQ3(classifiers4[i].polarity, weak_classifiers2[i].polarity, classifiers[i].polarity), 'p NOT EQUAL'\n",
    "        assert EQ3(classifiers4[i].error, weak_classifiers2[i].error, classifiers[i].error), 'e NOT EQUAL'\n",
    "        OK(f'classifier {i} is correct')\n",
    "    except AssertionError as e:\n",
    "        NOK('Classifiers are not equal')\n",
    "        print(e)\n",
    "        print('4', classifiers4[i])\n",
    "        print('1', classifiers[i])\n",
    "        print('2', weak_classifiers2[i])\n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created object, now training at 4.795163 seconds\n",
      "Starting to choose classifier\n",
      "At batch number:  0 :  Start time:  0.09859371185302734\n",
      "Memory for batch:  (58.1171875, 1446.0)\n",
      "At batch number:  1 :  Start time:  0.263134241104126\n",
      "Memory for batch:  (647.80712890625, 1446.0)\n",
      "At batch number:  2 :  Start time:  0.4236454963684082\n",
      "Memory for batch:  (647.3662109375, 1446.0)\n",
      "At batch number:  3 :  Start time:  0.5764758586883545\n",
      "Memory for batch:  (646.26416015625, 1446.0)\n",
      "At batch number:  4 :  Start time:  0.7311372756958008\n",
      "Memory for batch:  (647.3662109375, 1446.0)\n",
      "At batch number:  5 :  Start time:  0.8856208324432373\n",
      "Memory for batch:  (647.03955078125, 1446.0)\n",
      "At batch number:  6 :  Start time:  1.0397913455963135\n",
      "Memory for batch:  (647.3818359375, 1446.0)\n",
      "At batch number:  7 :  Start time:  1.2577593326568604\n",
      "Memory for batch:  (646.26806640625, 1446.0)\n",
      "At batch number:  8 :  Start time:  1.4109973907470703\n",
      "Memory for batch:  (647.3818359375, 1446.0)\n",
      "At batch number:  9 :  Start time:  1.5688178539276123\n",
      "Memory for batch:  (647.04345703125, 1446.0)\n",
      "At batch number:  10 :  Start time:  1.7224366664886475\n",
      "Memory for batch:  (646.6025390625, 1446.0)\n",
      "At batch number:  11 :  Start time:  1.8794894218444824\n",
      "Memory for batch:  (647.02392578125, 1446.0)\n",
      "At batch number:  12 :  Start time:  2.033613920211792\n",
      "Memory for batch:  (646.6064453125, 1446.0)\n",
      "At batch number:  13 :  Start time:  2.1847469806671143\n",
      "Memory for batch:  (647.04345703125, 1446.0)\n",
      "At batch number:  14 :  Start time:  2.3359389305114746\n",
      "Memory for batch:  (647.3818359375, 1446.0)\n",
      "At batch number:  15 :  Start time:  2.494204521179199\n",
      "Memory for batch:  (647.04345703125, 1446.0)\n",
      "Time taken: 2.729641 seconds\n",
      "Cell took: 7.525395 seconds\n"
     ]
    }
   ],
   "source": [
    "n_features = 16000\n",
    "n_samples = 15000\n",
    "s_t = time.time()\n",
    "\n",
    "X, y, weights = generate_data(n_features=n_features, n_samples=n_samples, floatornot=False)\n",
    "\n",
    "weak_classifiers = BestClassifier(X, y, weights, 1000, show_time=True, show_mem=True, debug=False, getClassifier=True, delete_unused=True, delta=0.000001)\n",
    "# weak_classifiers = BestClassifier(X, y, weights, 1000, show_time=True, show_mem=True, debug=False, getClassifier=False, delete_unused=True, delta=0.000001)\n",
    "print('Created object, now training at %f seconds' % (time.time() - s_t))\n",
    "BC, (classifiers4, LW, RW) = weak_classifiers.chooseClassifier()\n",
    "best_index, best_threshold, best_polarity, best_error = BC.feature_index, BC.threshold, BC.polarity, BC.error\n",
    "\n",
    "print('Cell took: %f seconds' % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise 'STOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained 1000 classifiers out of 16000\n",
      "Trained 2000 classifiers out of 16000\n",
      "Trained 3000 classifiers out of 16000\n",
      "Trained 4000 classifiers out of 16000\n",
      "Trained 5000 classifiers out of 16000\n",
      "Trained 6000 classifiers out of 16000\n",
      "Trained 7000 classifiers out of 16000\n",
      "Trained 8000 classifiers out of 16000\n",
      "Trained 9000 classifiers out of 16000\n",
      "Trained 10000 classifiers out of 16000\n",
      "Trained 11000 classifiers out of 16000\n",
      "Trained 12000 classifiers out of 16000\n",
      "Trained 13000 classifiers out of 16000\n",
      "Trained 14000 classifiers out of 16000\n",
      "Trained 15000 classifiers out of 16000\n",
      "Time taken: 277.268840 seconds\n",
      "Cell took: 277.270168 seconds\n"
     ]
    }
   ],
   "source": [
    "s_t = time.time()\n",
    "weak_classifiers2 = train_weak(X, y, None, weights)\n",
    "print('Cell took: %f seconds' % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#! dies already! 😏😒\n",
    "# s_t = time.time()\n",
    "# best_clf2, best_error2, best_accuracy2, aaa2 = select_best(weak_classifiers2, weights, X, y)\n",
    "\n",
    "# print('Cell took: %f seconds' % (time.time() - s_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBest classifier is not correct, but it's ok 😏😒\u001b[0m\n",
      "ϵ NOT EQUAL\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#! fails because previous died already! 😏😒\n",
    "try:\n",
    "    assert EQ(best_error, best_error2), 'ϵ NOT EQUAL'\n",
    "    assert EQ(best_threshold, best_clf2.threshold), 'θ NOT EQUAL'\n",
    "    assert EQ(best_polarity, best_clf2.polarity), 'p NOT EQUAL'\n",
    "    OK('Best classifier is correct')\n",
    "except AssertionError as e:\n",
    "    NOK(\"Best classifier is not correct, but it's ok 😏😒\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mClassifiers are equal, except for 8 classifiers\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "differences = []\n",
    "for i in range(len(classifiers4)):\n",
    "    try:\n",
    "        assert EQ(classifiers4[i].feature_index, weak_classifiers2[i].feature_index), 'index NOT EQUAL'\n",
    "        assert EQ(classifiers4[i].threshold, weak_classifiers2[i].threshold, permittivity=0.001), 'θ NOT EQUAL'\n",
    "        assert EQ(classifiers4[i].polarity, weak_classifiers2[i].polarity, permittivity=0.001), 'p NOT EQUAL'\n",
    "        assert EQ(classifiers4[i].error, weak_classifiers2[i].error, permittivity=0.001), 'e NOT EQUAL'\n",
    "        # OK(f'classifier {i} is correct')\n",
    "    except AssertionError as e:\n",
    "        # NOK('Classifiers are not equal')\n",
    "        # print(e)\n",
    "        # print('4', classifiers4[i])\n",
    "        # print('2', weak_classifiers2[i])\n",
    "        # print()\n",
    "        differences.append(i)\n",
    "\n",
    "OK('Classifiers are equal, except for %d classifiers' % len(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [ 2.31100000e+03 -1.02175319e+00  1.00000000e+00  4.87428665e-01]\n",
      "2 [ 2.31300000e+03 -1.02143836e+00 -1.02144836e+00  1.00000000e+00\n",
      "  4.87428769e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 1.31400000e+03 -1.35705221e+00  1.00000000e+00  4.91436005e-01]\n",
      "2 [ 1.31300000e+03 -1.35705127e+00 -1.35706127e+00  1.00000000e+00\n",
      "  4.91437265e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 5.34000000e+02 -1.82065535e+00  1.00000000e+00  4.92238462e-01]\n",
      "2 [ 1.40050000e+04  1.53930030e+00  1.53929030e+00 -1.00000000e+00\n",
      "  4.92238253e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 1.36550000e+04  1.36341846e+00 -1.00000000e+00  4.90879685e-01]\n",
      "2 [ 1.36670000e+04  1.36779858e+00  1.36778858e+00 -1.00000000e+00\n",
      "  4.90879320e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 8.95400000e+03  2.40293860e-01 -1.00000000e+00  4.87884402e-01]\n",
      "2 [ 8.95800000e+03  2.40481278e-01  2.40471278e-01 -1.00000000e+00\n",
      "  4.87884178e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 1.66800000e+03 -1.22020626e+00  1.00000000e+00  4.90470648e-01]\n",
      "2 [ 1.66900000e+03 -1.22009661e+00 -1.22010661e+00  1.00000000e+00\n",
      "  4.90470410e-01]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 0.         -3.98476982 -1.          0.49325895]\n",
      "2 [ 0.         -3.98476884 -3.98477884  1.          0.49325876]\n",
      "\u001b[32mit is so close\u001b[0m\n",
      "4 [ 0.         -3.94403815 -1.          0.4932586 ]\n",
      "2 [ 0.         -3.9440371  -3.9440471   1.          0.49325876]\n",
      "\u001b[32mit is so close\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in differences:\n",
    "    print('4', classifiers4[i])\n",
    "    print('2', weak_classifiers2[i])\n",
    "    OK('it is so close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
